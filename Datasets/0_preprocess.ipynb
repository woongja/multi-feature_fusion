{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5338d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤: /home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta_all.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file1 = '/home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta_file.csv'\n",
    "file2 = '/home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta_auto_tune.csv'\n",
    "output_path = '/home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta_all.csv'\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# ë°ì´í„° í•©ì¹˜ê¸°\n",
    "df_merged = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# ì €ì¥\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "print(f\"âœ… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23fa2d",
   "metadata": {},
   "source": [
    "### subset ë‚˜ëˆ„ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199b332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    270269\n",
      "eval     152900\n",
      "dev      115831\n",
      "Name: Split, dtype: int64\n",
      "\n",
      "âœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ: /home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta_subset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ğŸ” ê²½ë¡œ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "meta_path = \"/home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta.csv\"\n",
    "df = pd.read_csv(meta_path)\n",
    "\n",
    "# ğŸ“Œ ë¶„í•  ì»¬ëŸ¼ ì¶”ê°€\n",
    "df['Split'] = None\n",
    "\n",
    "# âœ… 1. Bonafide ë¶„í• \n",
    "# 1-1. CommonVoiceëŠ” eval\n",
    "df.loc[(df['label2'] == 'bonafide') & (df['group'] == 'TIMIT'), 'Split'] = 'eval'\n",
    "\n",
    "# 1-2. VCTK & LibriSpeech â†’ train/dev ë¶„í• \n",
    "real_train_dev = df[(df['label2'] == 'bonafide') & (df['group'].isin(['VCTK', 'LibriSpeech']))]\n",
    "train_idx, dev_idx = train_test_split(real_train_dev.index, test_size=0.3, random_state=42, shuffle=True)\n",
    "df.loc[train_idx, 'Split'] = 'train'\n",
    "df.loc[dev_idx, 'Split'] = 'dev'\n",
    "\n",
    "# âœ… 2. Spoof ë¶„í• \n",
    "spoof_df = df[df['label2'] == 'spoof']\n",
    "for group_name in spoof_df['group'].unique():\n",
    "    group_data = spoof_df[spoof_df['group'] == group_name]\n",
    "    \n",
    "    # 50% â†’ eval\n",
    "    group_eval_idx = group_data.sample(frac=0.5, random_state=42).index\n",
    "    df.loc[group_eval_idx, 'Split'] = 'eval'\n",
    "    \n",
    "    # ë‚˜ë¨¸ì§€ â†’ train/dev\n",
    "    remaining = group_data.drop(index=group_eval_idx)\n",
    "    group_train_idx, group_dev_idx = train_test_split(remaining.index, test_size=0.3, random_state=42)\n",
    "    df.loc[group_train_idx, 'Split'] = 'train'\n",
    "    df.loc[group_dev_idx, 'Split'] = 'dev'\n",
    "\n",
    "# âœ… ê²€ì¦\n",
    "print(df['Split'].value_counts())\n",
    "\n",
    "# ğŸ’¾ ì €ì¥\n",
    "output_path = \"/home/woongjae/noise-tracing/muti-feature_fusion/Datasets/meta_subset.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b6ae4",
   "metadata": {},
   "source": [
    "### Protocol íŒŒì¼ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8597c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('/home/woongjae/multi-feature_fusion/Datasets/meta_subset.csv')\n",
    "\n",
    "# í”„ë¡œí† ì½œ í…ìŠ¤íŠ¸ ë§Œë“¤ê¸° í•¨ìˆ˜\n",
    "def make_protocol_multi(df, subset_list, protocol_path):\n",
    "    # ì—¬ëŸ¬ subset í•„í„°ë§ (ì˜ˆ: train, dev)\n",
    "    proto_df = df[df['Subset'].str.lower().isin(subset_list)]\n",
    "    with open(protocol_path, 'w') as f:\n",
    "        for _, row in proto_df.iterrows():\n",
    "            # Train/dev ëª¨ë‘ 'Train'ìœ¼ë¡œ í†µì¼\n",
    "            f.write(f\"{row['file_path']}\\tTrain\\t{row['label1']}\\n\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ: train/dev í•©ì¹œ íŒŒì¼ ë§Œë“¤ê¸°\n",
    "make_protocol_multi(df, ['train', 'dev'], 'protocol_train_dev.txt')\n",
    "\n",
    "# evalì€ ê¸°ì¡´ëŒ€ë¡œ (ì°¸ê³ )\n",
    "make_protocol_multi(df, ['eval'], 'protocol_eval.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949fb3b",
   "metadata": {},
   "source": [
    "### protocol íŒŒì¼ ê²½ë¡œ ë°”ê¾¸ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c237938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²½ë¡œ ì¹˜í™˜ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: protocol_eval_f.txt\n"
     ]
    }
   ],
   "source": [
    "# í”„ë¡œí† ì½œ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ ê²½ë¡œ ì¼ê´„ ì¹˜í™˜\n",
    "# input_path = \"protocol_train_dev.txt\"   # ì›ë³¸ íŒŒì¼\n",
    "# output_path = \"protocol_train_dev_fixed.txt\"  # ì €ì¥í•  íŒŒì¼\n",
    "input_path = \"protocol_eval.txt\"   # ì›ë³¸ íŒŒì¼\n",
    "output_path = \"protocol_eval_f.txt\"  # ì €ì¥í•  íŒŒì¼\n",
    "old_prefix = \"home/woongjae/noise-tracing/muti-feature_fusion\"\n",
    "new_prefix = \"home/woongjae/multi-feature_fusion\"\n",
    "\n",
    "with open(input_path, \"r\") as fin, open(output_path, \"w\") as fout:\n",
    "    for line in fin:\n",
    "        # ê²½ë¡œ ì¹˜í™˜\n",
    "        new_line = line.replace(old_prefix, new_prefix)\n",
    "        fout.write(new_line)\n",
    "\n",
    "print(f\"âœ… ê²½ë¡œ ì¹˜í™˜ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac2540",
   "metadata": {},
   "source": [
    "### protocol íŒŒì¼ ë ˆì´ë¸” ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0649f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”„ë¡œí† ì½œ íŒŒì¼ ë¼ë²¨ ì¹˜í™˜ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: protocol_eval_f.txt\n"
     ]
    }
   ],
   "source": [
    "# protocol íŒŒì¼ì—ì„œ label1 ì¹˜í™˜(ìˆ˜ì •)\n",
    "# input_path = \"protocol_train_dev.txt\"    # ê¸°ì¡´ í”„ë¡œí† ì½œ íŒŒì¼ëª…\n",
    "# output_path = \"protocol_train_dev_fixed.txt\"   # ìˆ˜ì •ëœ íŒŒì¼ëª…\n",
    "\n",
    "input_path = \"protocol_eval.txt\"    # ê¸°ì¡´ í”„ë¡œí† ì½œ íŒŒì¼ëª…\n",
    "output_path = \"protocol_eval_f.txt\"   # ìˆ˜ì •ëœ íŒŒì¼ëª…\n",
    "\n",
    "# ì¹˜í™˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
    "replace_dict = {\n",
    "    \"high_pass_filter\": \"band_pass_filter\",\n",
    "    \"low_pass_filter\": \"band_pass_filter\",\n",
    "    \"pitch_shift\": \"manipulation\",\n",
    "    \"time_stretch\": \"manipulation\"\n",
    "}\n",
    "\n",
    "with open(input_path, \"r\") as fin, open(output_path, \"w\") as fout:\n",
    "    for line in fin:\n",
    "        items = line.strip().split('\\t')\n",
    "        if len(items) != 3:\n",
    "            fout.write(line)  # í¬ë§· ì´ìƒ ì¤„ì€ ê·¸ëŒ€ë¡œ ì¶œë ¥\n",
    "            continue\n",
    "        # label1 ì¹˜í™˜\n",
    "        label1 = replace_dict.get(items[2], items[2])\n",
    "        fout.write(f\"{items[0]}\\t{items[1]}\\t{label1}\\n\")\n",
    "\n",
    "print(f\"âœ… í”„ë¡œí† ì½œ íŒŒì¼ ë¼ë²¨ ì¹˜í™˜ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0e531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
