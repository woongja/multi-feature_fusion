{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b03c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f57e8",
   "metadata": {},
   "source": [
    "### Bonafide ë©”íƒ€ë°ì´í„° í•©ì¹˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ab9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "vctk_df = pd.read_csv('/home/woongjae/noise-tracing/new_dataset/meta_new_VCTK.csv')\n",
    "librispeech_df = pd.read_csv('/home/woongjae/noise-tracing/new_dataset/meta_new_LibriSpeech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f2a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µí•©\n",
    "merged_df = pd.concat([vctk_df, librispeech_df, commonvoice_df], ignore_index=True)\n",
    "\n",
    "# ì €ì¥\n",
    "merged_df.to_csv('meta_bonafide.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd719b",
   "metadata": {},
   "source": [
    "### spoof + bonafide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spoof_df = pd.read_csv('/home/woongjae/noise-tracing/new_dataset/meta_new_DSDCorpus.csv')\n",
    "bonafide_df = pd.read_csv('/home/woongjae/noise-tracing/new_dataset/meta_bonafide.csv')\n",
    "\n",
    "merged_df = pd.concat([spoof_df, bonafide_df], ignore_index=True)\n",
    "merged_df.to_csv('meta_bonafide_spoof.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a470f482",
   "metadata": {},
   "source": [
    "### ì „ì²´ ë©”íƒ€ íŒŒì¼ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "315ac117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜: 52700\n",
      "Label ë¶„í¬:\n",
      "bonafide    37500\n",
      "spoof       15200\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "meta_df = pd.read_csv('/home/woongjae/noise-tracing/new_dataset/meta_bonafide_spoof.csv')\n",
    "\n",
    "# 1. ì „ì²´ ìƒ˜í”Œ ìˆ˜\n",
    "total_samples = len(meta_df)\n",
    "print(f'ì „ì²´ ìƒ˜í”Œ ìˆ˜: {total_samples}')\n",
    "\n",
    "# 2. Label ë¶„í¬ í™•ì¸ (bonafide vs spoof)\n",
    "label_counts = meta_df['Label'].value_counts()\n",
    "print('Label ë¶„í¬:')\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58e501",
   "metadata": {},
   "source": [
    "### ë…¸ì´ì¦ˆ ë ˆì´ë¸” ì—´ ì¶”ê°€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005fd43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('/home/woongjae/noise-tracing/new_dataset/meta_bonafide_spoof.csv')\n",
    "\n",
    "# ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½: Label â†’ Label2\n",
    "meta_df = meta_df.rename(columns={'Label': 'Label2'})\n",
    "\n",
    "# ìƒˆ ì»¬ëŸ¼ Label1 ìƒì„± â†’ ëª¨ë“  ìƒ˜í”Œì€ ì²˜ìŒì—” 'clean'\n",
    "meta_df['Label1'] = 'clean'\n",
    "\n",
    "# ì €ì¥\n",
    "meta_df.to_csv('meta_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298e3eb",
   "metadata": {},
   "source": [
    "### ì „ì²´ ë…¸ì´ì¦ˆ ë©”íƒ€ íŒŒì¼ í•©ì¹˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… í†µí•© ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: /home/woongjae/noise-tracing/new_dataset/meta_all.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ“Œ Clean ë©”íƒ€ë°ì´í„°\n",
    "clean_path = \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_clean.csv\"\n",
    "df_clean = pd.read_csv(clean_path)\n",
    "\n",
    "# ğŸ“Œ ê° ë…¸ì´ì¦ˆ íƒ€ì…ë³„ ë©”íƒ€ë°ì´í„° ìˆ˜ë™ ì§€ì •\n",
    "noise_paths = [\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_background_noise.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_background_music.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_overlapping_speech.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_white_noise.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_pink_noise.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_pitch_shift.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_time_stretch.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_auto_tune.csv\",\n",
    "    \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_reverberation.csv\"\n",
    "]\n",
    "\n",
    "# ğŸ“¥ ì „ì²´ ë©”íƒ€ë°ì´í„° í†µí•©\n",
    "dfs = [df_clean] + [pd.read_csv(path) for path in noise_paths]\n",
    "df_total = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ğŸ’¾ ì €ì¥\n",
    "output_path = \"/home/woongjae/noise-tracing/new_dataset/meta_all.csv\"\n",
    "df_total.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… ìµœì¢… í†µí•© ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc3e7d3",
   "metadata": {},
   "source": [
    "### Train/Dev/Eval ì…‹ ë‚˜ëˆ„ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ğŸ” ê²½ë¡œ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "meta_path = \"/home/woongjae/noise-tracing/new_dataset/meta_total.csv\"\n",
    "df = pd.read_csv(meta_path)\n",
    "\n",
    "# ğŸ“Œ ë¶„í•  ì»¬ëŸ¼ ì¶”ê°€\n",
    "df['Split'] = None\n",
    "\n",
    "# âœ… 1. Bonafide ë¶„í• \n",
    "# 1-1. CommonVoiceëŠ” eval\n",
    "df.loc[(df['Label2'] == 'bonafide') & (df['Subset'] == 'CommonVoice'), 'Split'] = 'eval'\n",
    "\n",
    "# 1-2. VCTK & LibriSpeech â†’ train/dev ë¶„í• \n",
    "real_train_dev = df[(df['Label2'] == 'bonafide') & (df['Subset'].isin(['VCTK', 'LibriSpeech']))]\n",
    "train_idx, dev_idx = train_test_split(real_train_dev.index, test_size=0.2, random_state=42, shuffle=True)\n",
    "df.loc[train_idx, 'Split'] = 'train'\n",
    "df.loc[dev_idx, 'Split'] = 'dev'\n",
    "\n",
    "# âœ… 2. Spoof ë¶„í• \n",
    "spoof_df = df[df['Label2'] == 'spoof']\n",
    "for group_name in spoof_df['group'].unique():\n",
    "    group_data = spoof_df[spoof_df['group'] == group_name]\n",
    "    \n",
    "    # 50% â†’ eval\n",
    "    group_eval_idx = group_data.sample(frac=0.5, random_state=42).index\n",
    "    df.loc[group_eval_idx, 'Split'] = 'eval'\n",
    "    \n",
    "    # ë‚˜ë¨¸ì§€ â†’ train/dev\n",
    "    remaining = group_data.drop(index=group_eval_idx)\n",
    "    group_train_idx, group_dev_idx = train_test_split(remaining.index, test_size=0.2, random_state=42)\n",
    "    df.loc[group_train_idx, 'Split'] = 'train'\n",
    "    df.loc[group_dev_idx, 'Split'] = 'dev'\n",
    "\n",
    "# âœ… ê²€ì¦\n",
    "print(df['Split'].value_counts())\n",
    "\n",
    "# ğŸ’¾ ì €ì¥\n",
    "output_path = \"/home/woongjae/noise-tracing/new_dataset/meta_total_with_split.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411509b",
   "metadata": {},
   "source": [
    "### ì•ˆë§Œë“¤ì–´ì§„ íŒŒì¼ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e284259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â— ëˆ„ë½ëœ ìƒ˜í”Œ ìˆ˜: 2ê°œ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_path</th>\n",
       "      <th>utt</th>\n",
       "      <th>speaker ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>Group</th>\n",
       "      <th>Label2</th>\n",
       "      <th>Label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13587</th>\n",
       "      <td>/home/woongjae/noise-tracing/new_dataset/Datas...</td>\n",
       "      <td>TTS_VCTK_22_VITS_38</td>\n",
       "      <td>VCTK_22</td>\n",
       "      <td>Female</td>\n",
       "      <td>VITS-TTS</td>\n",
       "      <td>spoof</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47306</th>\n",
       "      <td>/home/woongjae/noise-tracing/new_dataset/Datas...</td>\n",
       "      <td>common_voice_en_20182997</td>\n",
       "      <td>ccf426b54d5a1d7c96254d4bbeb6c0da8d2923224687fe...</td>\n",
       "      <td>Male</td>\n",
       "      <td>CommonVoice</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               File_path  \\\n",
       "13587  /home/woongjae/noise-tracing/new_dataset/Datas...   \n",
       "47306  /home/woongjae/noise-tracing/new_dataset/Datas...   \n",
       "\n",
       "                            utt  \\\n",
       "13587       TTS_VCTK_22_VITS_38   \n",
       "47306  common_voice_en_20182997   \n",
       "\n",
       "                                              speaker ID  gender        Group  \\\n",
       "13587                                            VCTK_22  Female     VITS-TTS   \n",
       "47306  ccf426b54d5a1d7c96254d4bbeb6c0da8d2923224687fe...    Male  CommonVoice   \n",
       "\n",
       "         Label2 Label1  \n",
       "13587     spoof  clean  \n",
       "47306  bonafide  clean  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë©”íƒ€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "clean_meta = pd.read_csv(\"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_clean.csv\")\n",
    "reverb_meta = pd.read_csv(\"/home/woongjae/noise-tracing/new_dataset/meta_reverberation.csv\")\n",
    "\n",
    "# ê³µí†µ í˜•ì‹ ì •ë¦¬\n",
    "clean_utts = set(clean_meta['utt'])\n",
    "reverb_utts = set(reverb_meta['utt'].str.replace(\"_reverberation\", \"\", regex=False))\n",
    "\n",
    "# ëˆ„ë½ëœ í•­ëª©\n",
    "missing_utts = clean_utts - reverb_utts\n",
    "\n",
    "# ëˆ„ë½ëœ ìƒ˜í”Œ í™•ì¸\n",
    "missing_df = clean_meta[clean_meta['utt'].isin(missing_utts)]\n",
    "print(f\"â— ëˆ„ë½ëœ ìƒ˜í”Œ ìˆ˜: {len(missing_df)}ê°œ\")\n",
    "missing_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6e466",
   "metadata": {},
   "source": [
    "##### ì „ì²´ ë©”íƒ€ íŒŒì¼ í•©ì¹˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b41fde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë©”íƒ€íŒŒì¼ ë³‘í•© ì™„ë£Œ: /home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_all.csv\n"
     ]
    }
   ],
   "source": [
    "# ê²½ë¡œ ìˆ˜ì •: ì‹¤ì œ ë©”íƒ€íŒŒì¼ í´ë”\n",
    "meta_dir = \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile\"\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° íŒŒì¼ í•„í„°ë§\n",
    "meta_files = [f for f in os.listdir(meta_dir) if f.endswith(\".csv\") and \"meta\" in f]\n",
    "\n",
    "# ë³‘í•©\n",
    "merged_df = pd.concat([pd.read_csv(os.path.join(meta_dir, f)) for f in meta_files], ignore_index=True)\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = os.path.join(meta_dir, \"meta_all.csv\")\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… ë©”íƒ€íŒŒì¼ ë³‘í•© ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066accd",
   "metadata": {},
   "source": [
    "### ë°ì´í„°ì…‹ ë‚˜ëˆ„ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cd24c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woongjae/miniconda3/envs/asvspoof5/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: /home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_subset.csv\n"
     ]
    }
   ],
   "source": [
    "# ë©”íƒ€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "meta_path = \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_all.csv\"\n",
    "df = pd.read_csv(meta_path)\n",
    "\n",
    "# Subset ì»¬ëŸ¼ ì¶”ê°€\n",
    "df[\"Subset\"] = \"undefined\"\n",
    "\n",
    "# âœ… Bonafide ì²˜ë¦¬\n",
    "bonafide_df = df[df[\"Label2\"] == \"bonafide\"]\n",
    "\n",
    "# LibriSpeech + VCTK â†’ train/dev\n",
    "bv_df = bonafide_df[bonafide_df[\"Group\"].isin([\"LibriSpeech\", \"VCTK\"])]\n",
    "bv_shuffled = bv_df.sample(frac=1, random_state=42)\n",
    "n_train = int(len(bv_shuffled) * 0.75)\n",
    "train_idx = bv_shuffled.iloc[:n_train].index\n",
    "dev_idx = bv_shuffled.iloc[n_train:].index\n",
    "df.loc[train_idx, \"Subset\"] = \"train\"\n",
    "df.loc[dev_idx, \"Subset\"] = \"dev\"\n",
    "\n",
    "# CommonVoice â†’ eval\n",
    "df.loc[(df[\"Label2\"] == \"bonafide\") & (df[\"Group\"] == \"CommonVoice\"), \"Subset\"] = \"eval\"\n",
    "\n",
    "# âœ… Spoof ì²˜ë¦¬\n",
    "spoof_df = df[df[\"Label2\"] == \"spoof\"]\n",
    "for group in spoof_df[\"Group\"].unique():\n",
    "    gdf = spoof_df[spoof_df[\"Group\"] == group].sample(frac=1, random_state=42)\n",
    "    n = len(gdf)\n",
    "    n_train = int(n * 0.5)\n",
    "    n_dev = int(n * 0.25)\n",
    "    train_idx = gdf.iloc[:n_train].index\n",
    "    dev_idx = gdf.iloc[n_train:n_train + n_dev].index\n",
    "    eval_idx = gdf.iloc[n_train + n_dev:].index\n",
    "    df.loc[train_idx, \"Subset\"] = \"train\"\n",
    "    df.loc[dev_idx, \"Subset\"] = \"dev\"\n",
    "    df.loc[eval_idx, \"Subset\"] = \"eval\"\n",
    "\n",
    "# ì €ì¥\n",
    "out_path = \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_subset.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8a88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Percentage (%)   Count\n",
      "train           53.56  282250\n",
      "eval            26.19  138001\n",
      "dev             20.26  106749\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_subset.csv\")\n",
    "\n",
    "# Subset ë¹„ìœ¨ ë° ê°œìˆ˜ í™•ì¸\n",
    "subset_counts = df[\"Subset\"].value_counts(normalize=True).round(4) * 100\n",
    "subset_counts = subset_counts.rename(\"Percentage (%)\").to_frame()\n",
    "subset_counts[\"Count\"] = df[\"Subset\"].value_counts()\n",
    "\n",
    "print(subset_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d0e5e",
   "metadata": {},
   "source": [
    "### TIMIT ì €ì¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e43076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_clean.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_background_noise.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_overlapping_speech.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_white_noise.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_pitch_shift.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_background_music.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_auto_tune.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_time_stretch.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_reverberation.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "meta_pink_noise.csv: 6300ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\n",
      "\n",
      "âœ… ëª¨ë“  TIMIT ìƒ˜í”Œ ì „ì²´ ì»¬ëŸ¼ í¬í•¨ ë³‘í•© ì™„ë£Œ â†’ /home/woongjae/noise-tracing/new_dataset/Dataset/metafile/meta_timit_all.csv (ì´ 63000ê°œ)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "meta_dir = \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile\"\n",
    "output_path = os.path.join(meta_dir, \"meta_timit_all.csv\")\n",
    "\n",
    "# ëª¨ë“  meta_*.csv íŒŒì¼ íƒìƒ‰\n",
    "meta_files = [f for f in os.listdir(meta_dir)\n",
    "              if f.startswith(\"meta_\") and f.endswith(\".csv\") and f != \"meta_timit_all.csv\"]\n",
    "\n",
    "df_all_timit = []\n",
    "\n",
    "for fname in meta_files:\n",
    "    fpath = os.path.join(meta_dir, fname)\n",
    "    df = pd.read_csv(fpath)\n",
    "\n",
    "    if \"Group\" not in df.columns:\n",
    "        print(f\"[ìŠ¤í‚µ] {fname}: Group ì»¬ëŸ¼ ì—†ìŒ\")\n",
    "        continue\n",
    "\n",
    "    # TIMITë§Œ ì¶”ì¶œ + Subset ì»¬ëŸ¼ ëª…ì‹œì  ì¶”ê°€\n",
    "    df_timit = df[df[\"Group\"] == \"TIMIT\"].copy()\n",
    "    df_timit[\"Subset\"] = \"eval\"  # â† ì—¬ê¸°ì— ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€\n",
    "    df_all_timit.append(df_timit)\n",
    "\n",
    "    print(f\"{fname}: {len(df_timit)}ê°œ TIMIT ìƒ˜í”Œ ìˆ˜ì§‘ë¨\")\n",
    "\n",
    "# ë³‘í•© ë° ì €ì¥\n",
    "df_concat = pd.concat(df_all_timit, ignore_index=True)\n",
    "\n",
    "# ëª¨ë“  ì»¬ëŸ¼ ìœ ì§€ + ì €ì¥\n",
    "df_concat.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… ëª¨ë“  TIMIT ìƒ˜í”Œ ì „ì²´ ì»¬ëŸ¼ í¬í•¨ ë³‘í•© ì™„ë£Œ â†’ {output_path} (ì´ {len(df_concat)}ê°œ)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c21000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woongjae/miniconda3/envs/asvspoof5/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sub_meta + TIMIT ë³‘í•© ì™„ë£Œ â†’ /home/woongjae/noise-tracing/new_dataset/Dataset/metafile/Sub_meta_merged.csv (ì´ 490000ê°œ ìƒ˜í”Œ)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "meta_dir = \"/home/woongjae/noise-tracing/new_dataset/Dataset/metafile\"\n",
    "sub_meta_path = os.path.join(meta_dir, \"meta_subset.csv\")\n",
    "timit_path = os.path.join(meta_dir, \"meta_timit_all.csv\")\n",
    "merged_path = os.path.join(meta_dir, \"Sub_meta_merged.csv\")\n",
    "\n",
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_orig = pd.read_csv(sub_meta_path)\n",
    "df_timit = pd.read_csv(timit_path)\n",
    "\n",
    "# ì»¬ëŸ¼ í†µì¼ (í˜¹ì‹œ ëˆ„ë½ëœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì¶”ê°€)\n",
    "for col in df_orig.columns:\n",
    "    if col not in df_timit.columns:\n",
    "        df_timit[col] = \"\"\n",
    "\n",
    "# ë™ì¼í•œ ìˆœì„œë¡œ ì •ë ¬\n",
    "df_timit = df_timit[df_orig.columns]\n",
    "\n",
    "# ë³‘í•©\n",
    "df_combined = pd.concat([df_orig, df_timit], ignore_index=True)\n",
    "df_combined.to_csv(merged_path, index=False)\n",
    "\n",
    "print(f\"âœ… Sub_meta + TIMIT ë³‘í•© ì™„ë£Œ â†’ {merged_path} (ì´ {len(df_combined)}ê°œ ìƒ˜í”Œ)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b140a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asvspoof5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
